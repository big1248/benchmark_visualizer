#!/usr/bin/env python3
"""
ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
CSV íŒŒì¼ë“¤ì„ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ë³€í™˜í•˜ì—¬ ë¡œë”© ì†ë„ ê°œì„ 

ì‚¬ìš©ë²•:
1. data í´ë”ì— CSV íŒŒì¼ë“¤ì´ ìˆëŠ” ìƒíƒœì—ì„œ ì‹¤í–‰
2. python preprocess_data.py
3. ìƒì„±ëœ data.jsonì„ í”„ë¡œì íŠ¸ì— í¬í•¨

ë˜ëŠ” GitHubì—ì„œ ë‹¤ìš´ë¡œë“œ í›„ ë³€í™˜:
   python preprocess_data.py --download
"""

import json
import os
import sys
import glob
import re
from pathlib import Path

def parse_filename(filename):
    """íŒŒì¼ëª…ì—ì„œ ëª¨ë¸, ìƒì„¸ë„, í”„ë¡¬í”„íŒ…, í…ŒìŠ¤íŠ¸ëª… ì¶”ì¶œ"""
    name = Path(filename).stem
    parts = name.split('_')
    
    return {
        'model': parts[0] if len(parts) > 0 else 'Unknown',
        'detail': parts[1] if len(parts) > 1 else 'unknown',
        'prompting': parts[2] if len(parts) > 2 else 'unknown',
        'testname': '_'.join(parts[3:]) if len(parts) > 3 else 'Unknown'
    }

def process_csv_files(data_dir='./data', output_file='./data.json'):
    """CSV íŒŒì¼ë“¤ì„ JSONìœ¼ë¡œ ë³€í™˜"""
    import csv
    
    all_data = []
    csv_files = glob.glob(os.path.join(data_dir, '*.csv'))
    
    print(f"ğŸ“‚ {len(csv_files)}ê°œ CSV íŒŒì¼ ë°œê²¬")
    
    for i, filepath in enumerate(csv_files):
        filename = os.path.basename(filepath)
        file_info = parse_filename(filename)
        
        try:
            with open(filepath, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                
                for row in reader:
                    # í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œ (ìš©ëŸ‰ ìµœì í™”)
                    processed = {
                        'id': row.get('ID', ''),
                        'model': row.get('ëª¨ë¸ëª…', file_info['model']),
                        'test': row.get('Test Name', file_info['testname']),
                        'year': row.get('Year', ''),
                        'session': row.get('Session', ''),
                        'subject': row.get('Subject', ''),
                        'question': row.get('Question', ''),
                        'correct': row.get('ì •ë‹µì—¬ë¶€', '') in ['True', 'true', '1', True],
                        'law': row.get('law', ''),
                        'image': row.get('image', ''),
                        'time': float(row.get('ë¬¸ì œë‹¹í‰ê· ì‹œê°„(ì´ˆ)', 0) or 0),
                        'inputTokens': int(row.get('ì…ë ¥í† í°', 0) or 0),
                        'outputTokens': int(row.get('ì¶œë ¥í† í°', 0) or 0),
                        'cost': float(row.get('ë¹„ìš©($)', 0) or 0),
                        'detail': file_info['detail'],
                        'prompting': file_info['prompting']
                    }
                    
                    all_data.append(processed)
        
        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜ ({filename}): {e}")
        
        # ì§„í–‰ë¥  í‘œì‹œ
        if (i + 1) % 50 == 0:
            print(f"   ì²˜ë¦¬ ì¤‘... {i + 1}/{len(csv_files)}")
    
    print(f"âœ… ì´ {len(all_data):,}ê°œ ë ˆì½”ë“œ ì²˜ë¦¬ ì™„ë£Œ")
    
    # JSON ì €ì¥
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_data, f, ensure_ascii=False)
    
    # íŒŒì¼ í¬ê¸° í™•ì¸
    file_size = os.path.getsize(output_file) / (1024 * 1024)
    print(f"ğŸ“ {output_file} ì €ì¥ ì™„ë£Œ ({file_size:.1f} MB)")
    
    # ì••ì¶• ë²„ì „ë„ ìƒì„±
    import gzip
    compressed_file = output_file + '.gz'
    with open(output_file, 'rb') as f_in:
        with gzip.open(compressed_file, 'wb') as f_out:
            f_out.writelines(f_in)
    
    compressed_size = os.path.getsize(compressed_file) / (1024 * 1024)
    print(f"ğŸ“¦ {compressed_file} ì €ì¥ ì™„ë£Œ ({compressed_size:.1f} MB)")
    
    return all_data

def download_and_process():
    """GitHubì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ í›„ ì²˜ë¦¬"""
    import requests
    import zipfile
    import shutil
    
    repo = "big1248/benchmark_visualizer"
    tag = "v2.2.0"
    url = f"https://github.com/{repo}/releases/download/{tag}/data.zip"
    
    print(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: {url}")
    
    response = requests.get(url, stream=True)
    response.raise_for_status()
    
    # ZIP íŒŒì¼ ì €ì¥
    with open('data.zip', 'wb') as f:
        for chunk in response.iter_content(chunk_size=8192):
            f.write(chunk)
    
    print("ğŸ“‚ ì••ì¶• í•´ì œ ì¤‘...")
    with zipfile.ZipFile('data.zip', 'r') as zip_ref:
        zip_ref.extractall('.')
    
    os.remove('data.zip')
    
    # ì²˜ë¦¬
    process_csv_files()
    
    # data í´ë” ì •ë¦¬ (ì„ íƒì )
    # shutil.rmtree('./data')

def create_summary_json(all_data, output_file='./summary.json'):
    """ìš”ì•½ í†µê³„ JSON ìƒì„± (ë¹ ë¥¸ ì´ˆê¸° ë¡œë”©ìš©)"""
    
    # ëª¨ë¸ë³„ í†µê³„
    model_stats = {}
    test_stats = {}
    
    for row in all_data:
        model = row['model']
        test = row['test']
        
        # ëª¨ë¸ë³„
        if model not in model_stats:
            model_stats[model] = {'total': 0, 'correct': 0}
        model_stats[model]['total'] += 1
        if row['correct']:
            model_stats[model]['correct'] += 1
        
        # í…ŒìŠ¤íŠ¸ë³„
        if test not in test_stats:
            test_stats[test] = {'total': 0, 'correct': 0}
        test_stats[test]['total'] += 1
        if row['correct']:
            test_stats[test]['correct'] += 1
    
    summary = {
        'totalRecords': len(all_data),
        'models': {k: {**v, 'accuracy': v['correct'] / v['total'] * 100} for k, v in model_stats.items()},
        'tests': {k: {**v, 'accuracy': v['correct'] / v['total'] * 100} for k, v in test_stats.items()}
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“Š {output_file} ì €ì¥ ì™„ë£Œ")
    
    return summary

if __name__ == '__main__':
    if '--download' in sys.argv:
        download_and_process()
    else:
        if os.path.exists('./data'):
            data = process_csv_files()
            create_summary_json(data)
        else:
            print("âŒ data í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("   --download ì˜µì…˜ìœ¼ë¡œ GitHubì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜")
            print("   data í´ë”ì— CSV íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
